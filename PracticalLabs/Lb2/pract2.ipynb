{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dear', 'Eva', ',', 'It', 'will', 'be', 'almost', 'a', 'month', 'since', 'you', 'wrote', 'to', 'me', 'and', 'you', 'have', 'possibly', 'forgotten', 'your', 'state', 'of', 'mind', '(', 'I', 'doubt', 'it', 'though', ')', '.', 'You', 'seem', 'the', 'same', 'as', 'always', ',', 'and', 'being', 'you', ',', 'hate', 'every', 'minute', 'of', 'it', '.', 'Don', '’', 't', '!', 'Learn', 'to', 'say', '“', 'Fuck', 'You', '”', 'to', 'the', 'world', 'once', 'in', 'a', 'while', '.', 'You', 'have', 'every', 'right', 'to', '.', 'Just', 'stop', 'thinking', ',', 'worrying', ',', 'looking', 'over', 'your', 'shoulder', ',', 'wondering', ',', 'doubting', ',', 'fearing', ',', 'hurting', ',', 'hoping', 'for', 'some', 'easy', 'way', 'out', ',', 'struggling', ',', 'grasping', ',', 'confusing', ',', 'itching', ',', 'scratching', ',', 'mumbling', ',', 'bumbling', ',', 'grumbling', ',', 'humbling', ',', 'stumbling', ',', 'numbling', ',', 'rambling', ',', 'gambling', ',', 'tumbling', ',', 'scumbling', ',', 'scrambling', ',', 'hitching', ',', 'hatching', ',', 'bitching', ',', 'moaning', ',', 'groaning', ',', 'honing', ',', 'boning', ',', 'horse-shitting', ',', 'hair-splitting', ',', 'nit-picking', ',', 'piss-trickling', ',', 'nose', 'sticking', ',', 'ass-gouging', ',', 'eyeball-poking', ',', 'finger-pointing', ',', 'alleyway-sneaking', ',', 'long', 'waiting', ',', 'small', 'stepping', ',', 'evil-eyeing', ',', 'back-scratching', ',', 'searching', ',', 'perching', ',', 'besmirching', ',', 'grinding', ',', 'grinding', ',', 'grinding', 'away', 'at', 'yourself', '.', 'Stop', 'it', 'and', 'just', 'DO', 'From', 'your', 'description', ',', 'and', 'from', 'what', 'I', 'know', 'of', 'your', 'previous', 'work', 'and', 'your', 'ability', ';', 'the', 'work', 'you', 'are', 'doing', 'sounds', 'very', 'good', '“', 'Drawing', '–', 'clean', '–', 'clear', 'but', 'crazy', 'like', 'machines', ',', 'larger', 'and', 'bolder…', 'real', 'nonsense.', '”', 'That', 'sounds', 'fine', ',', 'wonderful', '—', 'real', 'nonsense', '.', 'Do', 'more', '.', 'More', 'nonsensical', ',', 'more', 'crazy', ',', 'more', 'machines', ',', 'more', 'breasts', ',', 'penises', ',', 'cunts', ',', 'whatever', '—', 'make', 'them', 'abound', 'with', 'nonsense', '.', 'Try', 'and', 'tickle', 'something', 'inside', 'you', ',', 'your', '“', 'weird', 'humor.', '”', 'You', 'belong', 'in', 'the', 'most', 'secret', 'part', 'of', 'you', '.', 'Don', '’', 't', 'worry', 'about', 'cool', ',', 'make', 'your', 'own', 'uncool', '.', 'Make', 'your', 'own', ',', 'your', 'own', 'world', '.', 'If', 'you', 'fear', ',', 'make', 'it', 'work', 'for', 'you', '—', 'draw', '&', 'paint', 'your', 'fear', '&', 'anxiety', '.', 'And', 'stop', 'worrying', 'about', 'big', ',', 'deep', 'things', 'such', 'as', '“', 'to', 'decide', 'on', 'a', 'purpose', 'and', 'way', 'of', 'life', ',', 'a', 'consistant', 'approach', 'to', 'even', 'some', 'impossible', 'end', 'or', 'even', 'an', 'imagined', 'end.', '”', 'You', 'must', 'practice', 'being', 'stupid', ',', 'dumb', ',', 'unthinking', ',', 'empty', '.', 'Then', 'you', 'will', 'be', 'able', 'to', 'DO', 'I', 'have', 'much', 'confidence', 'in', 'you', 'and', 'even', 'though', 'you', 'are', 'tormenting', 'yourself', ',', 'the', 'work', 'you', 'do', 'is', 'very', 'good', '.', 'Try', 'to', 'do', 'some', 'BAD', 'work', '—', 'the', 'worst', 'you', 'can', 'think', 'of', 'and', 'see', 'what', 'happens', 'but', 'mainly', 'relax', 'and', 'let', 'everything', 'go', 'to', 'hell', '—', 'you', 'are', 'not', 'responsible', 'for', 'the', 'world', '—', 'you', 'are', 'only', 'responsible', 'for', 'your', 'work', '—', 'so', 'DO', 'IT', '.', 'And', 'don', '’', 't', 'think', 'that', 'your', 'work', 'has', 'to', 'conform', 'to', 'any', 'preconceived', 'form', ',', 'idea', 'or', 'flavor', '.', 'It', 'can', 'be', 'anything', 'you', 'want', 'it', 'to', 'be', '.', 'But', 'if', 'life', 'would', 'be', 'easier', 'for', 'you', 'if', 'you', 'stopped', 'working', '—', 'then', 'stop', '.', 'Don', '’', 't', 'punish', 'yourself', '.', 'However', ',', 'I', 'think', 'that', 'it', 'is', 'so', 'deeply', 'engrained', 'in', 'you', 'that', 'it', 'would', 'be', 'easier', 'to', 'DO', 'It', 'seems', 'I', 'do', 'understand', 'your', 'attitude', 'somewhat', ',', 'anyway', ',', 'because', 'I', 'go', 'through', 'a', 'similar', 'process', 'every', 'so', 'often', '.', 'I', 'have', 'an', '“', 'Agonizing', 'Reappraisal', '”', 'of', 'my', 'work', 'and', 'change', 'everything', 'as', 'much', 'as', 'possible', '—', 'and', 'hate', 'everything', 'I', '’', 've', 'done', ',', 'and', 'try', 'to', 'do', 'something', 'entirely', 'different', 'and', 'better', '.', 'Maybe', 'that', 'kind', 'of', 'process', 'is', 'necessary', 'to', 'me', ',', 'pushing', 'me', 'on', 'and', 'on', '.', 'The', 'feeling', 'that', 'I', 'can', 'do', 'better', 'than', 'that', 'shit', 'I', 'just', 'did', '.', 'Maybe', 'you', 'need', 'your', 'agony', 'to', 'accomplish', 'what', 'you', 'do', '.', 'And', 'maybe', 'it', 'goads', 'you', 'on', 'to', 'do', 'better', '.', 'But', 'it', 'is', 'very', 'painful', 'I', 'know', '.', 'It', 'would', 'be', 'better', 'if', 'you', 'had', 'the', 'confidence', 'just', 'to', 'do', 'the', 'stuff', 'and', 'not', 'even', 'think', 'about', 'it', '.', 'Can', '’', 't', 'you', 'leave', 'the', '“', 'world', '”', 'and', '“', 'ART', '”', 'alone', 'and', 'also', 'quit', 'fondling', 'your', 'ego', '.', 'I', 'know', 'that', 'you', '(', 'or', 'anyone', ')', 'can', 'only', 'work', 'so', 'much', 'and', 'the', 'rest', 'of', 'the', 'time', 'you', 'are', 'left', 'with', 'your', 'thoughts', '.', 'But', 'when', 'you', 'work', 'or', 'before', 'your', 'work', 'you', 'have', 'to', 'empty', 'your', 'mind', 'and', 'concentrate', 'on', 'what', 'you', 'are', 'doing', '.', 'After', 'you', 'do', 'something', 'it', 'is', 'done', 'and', 'that', '’', 's', 'that', '.', 'After', 'a', 'while', 'you', 'can', 'see', 'some', 'are', 'better', 'than', 'others', 'but', 'also', 'you', 'can', 'see', 'what', 'direction', 'you', 'are', 'going', '.', 'I', '’', 'm', 'sure', 'you', 'know', 'all', 'that', '.', 'You', 'also', 'must', 'know', 'that', 'you', 'don', '’', 't', 'have', 'to', 'justify', 'your', 'work', '—', 'not', 'even', 'to', 'yourself', '.', 'Well', ',', 'you', 'know', 'I', 'admire', 'your', 'work', 'greatly', 'and', 'can', '’', 't', 'understand', 'why', 'you', 'are', 'so', 'bothered', 'by', 'it', '.', 'But', 'you', 'can', 'see', 'the', 'next', 'ones', '&', 'I', 'can', '’', 't', '.', 'You', 'also', 'must', 'believe', 'in', 'your', 'ability', '.', 'I', 'think', 'you', 'do', '.', 'So', 'try', 'the', 'most', 'outrageous', 'things', 'you', 'can', '—', 'shock', 'yourself', '.', 'You', 'have', 'at', 'your', 'power', 'the', 'ability', 'to', 'do', 'anything', '.', 'I', 'would', 'like', 'to', 'see', 'your', 'work', 'and', 'will', 'have', 'to', 'be', 'content', 'to', 'wait', 'until', 'Aug', 'or', 'Sept', '.', 'I', 'have', 'seen', 'photos', 'of', 'some', 'of', 'Tom', '’', 's', 'new', 'things', 'at', 'Lucy', '’', 's', '.', 'They', 'are', 'very', 'impressive', '—', 'especially', 'the', 'ones', 'with', 'the', 'more', 'rigorous', 'form', ';', 'the', 'simpler', 'ones', '.', 'I', 'guess', 'he', '’', 'll', 'send', 'some', 'more', 'later', 'on', '.', 'Let', 'me', 'know', 'how', 'the', 'shows', 'are', 'going', 'and', 'that', 'kind', 'of', 'stuff', '.', 'My', 'work', 'has', 'changed', 'since', 'you', 'left', 'and', 'it', 'is', 'much', 'better', '.', 'I', 'will', 'be', 'having', 'a', 'show', 'May', '4–29', 'at', 'the', 'Daniels', 'Gallery', '17', 'E', '64th', 'St', '(', 'where', 'Emmerich', 'was', ')', ',', 'I', 'wish', 'you', 'could', 'be', 'there', '.', 'Much', 'love', 'to', 'you', 'both', '.', 'Sol']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sayed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sayed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure punkt is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def tokenize_text_file(file_path):\n",
    "    \"\"\"Tokenizes the text in the given file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        tokens = word_tokenize(text)\n",
    "        return tokens\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} was not found.\")\n",
    "        return []\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error: Could not decode the file {file_path} due to encoding issue. {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to your text file\n",
    "    file_path = r\"F:\\M.Tech_CollgeMaterials\\CodeLLM\\PracticalLabs\\Lb2\\letter.txt\"  \n",
    "\n",
    "    # Call the function to tokenize the file content\n",
    "    tokens = tokenize_text_file(file_path)\n",
    "\n",
    "    if tokens:\n",
    "        print(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens:\n",
      "['Dear', 'Eva', ',', 'It', 'will', 'be', 'almost', 'a', 'month', 'since', 'you', 'wrote', 'to', 'me', 'and', 'you', 'have', 'possibly', 'forgotten', 'your', 'state', 'of', 'mind', '(', 'I', 'doubt', 'it', 'though', ')', '.', 'You', 'seem', 'the', 'same', 'as', 'always', ',', 'and', 'being', 'you', ',', 'hate', 'every', 'minute', 'of', 'it', '.', 'Don', '’', 't', '!', 'Learn', 'to', 'say', '“', 'Fuck', 'You', '”', 'to', 'the', 'world', 'once', 'in', 'a', 'while', '.', 'You', 'have', 'every', 'right', 'to', '.', 'Just', 'stop', 'thinking', ',', 'worrying', ',', 'looking', 'over', 'your', 'shoulder', ',', 'wondering', ',', 'doubting', ',', 'fearing', ',', 'hurting', ',', 'hoping', 'for', 'some', 'easy', 'way', 'out', ',', 'struggling', ',', 'grasping', ',', 'confusing', ',', 'itching', ',', 'scratching', ',', 'mumbling', ',', 'bumbling', ',', 'grumbling', ',', 'humbling', ',', 'stumbling', ',', 'numbling', ',', 'rambling', ',', 'gambling', ',', 'tumbling', ',', 'scumbling', ',', 'scrambling', ',', 'hitching', ',', 'hatching', ',', 'bitching', ',', 'moaning', ',', 'groaning', ',', 'honing', ',', 'boning', ',', 'horse-shitting', ',', 'hair-splitting', ',', 'nit-picking', ',', 'piss-trickling', ',', 'nose', 'sticking', ',', 'ass-gouging', ',', 'eyeball-poking', ',', 'finger-pointing', ',', 'alleyway-sneaking', ',', 'long', 'waiting', ',', 'small', 'stepping', ',', 'evil-eyeing', ',', 'back-scratching', ',', 'searching', ',', 'perching', ',', 'besmirching', ',', 'grinding', ',', 'grinding', ',', 'grinding', 'away', 'at', 'yourself', '.', 'Stop', 'it', 'and', 'just', 'DO', 'From', 'your', 'description', ',', 'and', 'from', 'what', 'I', 'know', 'of', 'your', 'previous', 'work', 'and', 'your', 'ability', ';', 'the', 'work', 'you', 'are', 'doing', 'sounds', 'very', 'good', '“', 'Drawing', '–', 'clean', '–', 'clear', 'but', 'crazy', 'like', 'machines', ',', 'larger', 'and', 'bolder…', 'real', 'nonsense.', '”', 'That', 'sounds', 'fine', ',', 'wonderful', '—', 'real', 'nonsense', '.', 'Do', 'more', '.', 'More', 'nonsensical', ',', 'more', 'crazy', ',', 'more', 'machines', ',', 'more', 'breasts', ',', 'penises', ',', 'cunts', ',', 'whatever', '—', 'make', 'them', 'abound', 'with', 'nonsense', '.', 'Try', 'and', 'tickle', 'something', 'inside', 'you', ',', 'your', '“', 'weird', 'humor.', '”', 'You', 'belong', 'in', 'the', 'most', 'secret', 'part', 'of', 'you', '.', 'Don', '’', 't', 'worry', 'about', 'cool', ',', 'make', 'your', 'own', 'uncool', '.', 'Make', 'your', 'own', ',', 'your', 'own', 'world', '.', 'If', 'you', 'fear', ',', 'make', 'it', 'work', 'for', 'you', '—', 'draw', '&', 'paint', 'your', 'fear', '&', 'anxiety', '.', 'And', 'stop', 'worrying', 'about', 'big', ',', 'deep', 'things', 'such', 'as', '“', 'to', 'decide', 'on', 'a', 'purpose', 'and', 'way', 'of', 'life', ',', 'a', 'consistant', 'approach', 'to', 'even', 'some', 'impossible', 'end', 'or', 'even', 'an', 'imagined', 'end.', '”', 'You', 'must', 'practice', 'being', 'stupid', ',', 'dumb', ',', 'unthinking', ',', 'empty', '.', 'Then', 'you', 'will', 'be', 'able', 'to', 'DO', 'I', 'have', 'much', 'confidence', 'in', 'you', 'and', 'even', 'though', 'you', 'are', 'tormenting', 'yourself', ',', 'the', 'work', 'you', 'do', 'is', 'very', 'good', '.', 'Try', 'to', 'do', 'some', 'BAD', 'work', '—', 'the', 'worst', 'you', 'can', 'think', 'of', 'and', 'see', 'what', 'happens', 'but', 'mainly', 'relax', 'and', 'let', 'everything', 'go', 'to', 'hell', '—', 'you', 'are', 'not', 'responsible', 'for', 'the', 'world', '—', 'you', 'are', 'only', 'responsible', 'for', 'your', 'work', '—', 'so', 'DO', 'IT', '.', 'And', 'don', '’', 't', 'think', 'that', 'your', 'work', 'has', 'to', 'conform', 'to', 'any', 'preconceived', 'form', ',', 'idea', 'or', 'flavor', '.', 'It', 'can', 'be', 'anything', 'you', 'want', 'it', 'to', 'be', '.', 'But', 'if', 'life', 'would', 'be', 'easier', 'for', 'you', 'if', 'you', 'stopped', 'working', '—', 'then', 'stop', '.', 'Don', '’', 't', 'punish', 'yourself', '.', 'However', ',', 'I', 'think', 'that', 'it', 'is', 'so', 'deeply', 'engrained', 'in', 'you', 'that', 'it', 'would', 'be', 'easier', 'to', 'DO', 'It', 'seems', 'I', 'do', 'understand', 'your', 'attitude', 'somewhat', ',', 'anyway', ',', 'because', 'I', 'go', 'through', 'a', 'similar', 'process', 'every', 'so', 'often', '.', 'I', 'have', 'an', '“', 'Agonizing', 'Reappraisal', '”', 'of', 'my', 'work', 'and', 'change', 'everything', 'as', 'much', 'as', 'possible', '—', 'and', 'hate', 'everything', 'I', '’', 've', 'done', ',', 'and', 'try', 'to', 'do', 'something', 'entirely', 'different', 'and', 'better', '.', 'Maybe', 'that', 'kind', 'of', 'process', 'is', 'necessary', 'to', 'me', ',', 'pushing', 'me', 'on', 'and', 'on', '.', 'The', 'feeling', 'that', 'I', 'can', 'do', 'better', 'than', 'that', 'shit', 'I', 'just', 'did', '.', 'Maybe', 'you', 'need', 'your', 'agony', 'to', 'accomplish', 'what', 'you', 'do', '.', 'And', 'maybe', 'it', 'goads', 'you', 'on', 'to', 'do', 'better', '.', 'But', 'it', 'is', 'very', 'painful', 'I', 'know', '.', 'It', 'would', 'be', 'better', 'if', 'you', 'had', 'the', 'confidence', 'just', 'to', 'do', 'the', 'stuff', 'and', 'not', 'even', 'think', 'about', 'it', '.', 'Can', '’', 't', 'you', 'leave', 'the', '“', 'world', '”', 'and', '“', 'ART', '”', 'alone', 'and', 'also', 'quit', 'fondling', 'your', 'ego', '.', 'I', 'know', 'that', 'you', '(', 'or', 'anyone', ')', 'can', 'only', 'work', 'so', 'much', 'and', 'the', 'rest', 'of', 'the', 'time', 'you', 'are', 'left', 'with', 'your', 'thoughts', '.', 'But', 'when', 'you', 'work', 'or', 'before', 'your', 'work', 'you', 'have', 'to', 'empty', 'your', 'mind', 'and', 'concentrate', 'on', 'what', 'you', 'are', 'doing', '.', 'After', 'you', 'do', 'something', 'it', 'is', 'done', 'and', 'that', '’', 's', 'that', '.', 'After', 'a', 'while', 'you', 'can', 'see', 'some', 'are', 'better', 'than', 'others', 'but', 'also', 'you', 'can', 'see', 'what', 'direction', 'you', 'are', 'going', '.', 'I', '’', 'm', 'sure', 'you', 'know', 'all', 'that', '.', 'You', 'also', 'must', 'know', 'that', 'you', 'don', '’', 't', 'have', 'to', 'justify', 'your', 'work', '—', 'not', 'even', 'to', 'yourself', '.', 'Well', ',', 'you', 'know', 'I', 'admire', 'your', 'work', 'greatly', 'and', 'can', '’', 't', 'understand', 'why', 'you', 'are', 'so', 'bothered', 'by', 'it', '.', 'But', 'you', 'can', 'see', 'the', 'next', 'ones', '&', 'I', 'can', '’', 't', '.', 'You', 'also', 'must', 'believe', 'in', 'your', 'ability', '.', 'I', 'think', 'you', 'do', '.', 'So', 'try', 'the', 'most', 'outrageous', 'things', 'you', 'can', '—', 'shock', 'yourself', '.', 'You', 'have', 'at', 'your', 'power', 'the', 'ability', 'to', 'do', 'anything', '.', 'I', 'would', 'like', 'to', 'see', 'your', 'work', 'and', 'will', 'have', 'to', 'be', 'content', 'to', 'wait', 'until', 'Aug', 'or', 'Sept', '.', 'I', 'have', 'seen', 'photos', 'of', 'some', 'of', 'Tom', '’', 's', 'new', 'things', 'at', 'Lucy', '’', 's', '.', 'They', 'are', 'very', 'impressive', '—', 'especially', 'the', 'ones', 'with', 'the', 'more', 'rigorous', 'form', ';', 'the', 'simpler', 'ones', '.', 'I', 'guess', 'he', '’', 'll', 'send', 'some', 'more', 'later', 'on', '.', 'Let', 'me', 'know', 'how', 'the', 'shows', 'are', 'going', 'and', 'that', 'kind', 'of', 'stuff', '.', 'My', 'work', 'has', 'changed', 'since', 'you', 'left', 'and', 'it', 'is', 'much', 'better', '.', 'I', 'will', 'be', 'having', 'a', 'show', 'May', '4–29', 'at', 'the', 'Daniels', 'Gallery', '17', 'E', '64th', 'St', '(', 'where', 'Emmerich', 'was', ')', ',', 'I', 'wish', 'you', 'could', 'be', 'there', '.', 'Much', 'love', 'to', 'you', 'both', '.', 'Sol']\n",
      "\n",
      "Stemmed Tokens:\n",
      "['dear', 'eva', ',', 'it', 'will', 'be', 'almost', 'a', 'month', 'sinc', 'you', 'wrote', 'to', 'me', 'and', 'you', 'have', 'possibl', 'forgotten', 'your', 'state', 'of', 'mind', '(', 'i', 'doubt', 'it', 'though', ')', '.', 'you', 'seem', 'the', 'same', 'as', 'alway', ',', 'and', 'be', 'you', ',', 'hate', 'everi', 'minut', 'of', 'it', '.', 'don', '’', 't', '!', 'learn', 'to', 'say', '“', 'fuck', 'you', '”', 'to', 'the', 'world', 'onc', 'in', 'a', 'while', '.', 'you', 'have', 'everi', 'right', 'to', '.', 'just', 'stop', 'think', ',', 'worri', ',', 'look', 'over', 'your', 'shoulder', ',', 'wonder', ',', 'doubt', ',', 'fear', ',', 'hurt', ',', 'hope', 'for', 'some', 'easi', 'way', 'out', ',', 'struggl', ',', 'grasp', ',', 'confus', ',', 'itch', ',', 'scratch', ',', 'mumbl', ',', 'bumbl', ',', 'grumbl', ',', 'humbl', ',', 'stumbl', ',', 'numbl', ',', 'rambl', ',', 'gambl', ',', 'tumbl', ',', 'scumbl', ',', 'scrambl', ',', 'hitch', ',', 'hatch', ',', 'bitch', ',', 'moan', ',', 'groan', ',', 'hone', ',', 'bone', ',', 'horse-shit', ',', 'hair-split', ',', 'nit-pick', ',', 'piss-trickl', ',', 'nose', 'stick', ',', 'ass-goug', ',', 'eyeball-pok', ',', 'finger-point', ',', 'alleyway-sneak', ',', 'long', 'wait', ',', 'small', 'step', ',', 'evil-ey', ',', 'back-scratch', ',', 'search', ',', 'perch', ',', 'besmirch', ',', 'grind', ',', 'grind', ',', 'grind', 'away', 'at', 'yourself', '.', 'stop', 'it', 'and', 'just', 'do', 'from', 'your', 'descript', ',', 'and', 'from', 'what', 'i', 'know', 'of', 'your', 'previou', 'work', 'and', 'your', 'abil', ';', 'the', 'work', 'you', 'are', 'do', 'sound', 'veri', 'good', '“', 'draw', '–', 'clean', '–', 'clear', 'but', 'crazi', 'like', 'machin', ',', 'larger', 'and', 'bolder…', 'real', 'nonsense.', '”', 'that', 'sound', 'fine', ',', 'wonder', '—', 'real', 'nonsens', '.', 'do', 'more', '.', 'more', 'nonsens', ',', 'more', 'crazi', ',', 'more', 'machin', ',', 'more', 'breast', ',', 'penis', ',', 'cunt', ',', 'whatev', '—', 'make', 'them', 'abound', 'with', 'nonsens', '.', 'tri', 'and', 'tickl', 'someth', 'insid', 'you', ',', 'your', '“', 'weird', 'humor.', '”', 'you', 'belong', 'in', 'the', 'most', 'secret', 'part', 'of', 'you', '.', 'don', '’', 't', 'worri', 'about', 'cool', ',', 'make', 'your', 'own', 'uncool', '.', 'make', 'your', 'own', ',', 'your', 'own', 'world', '.', 'if', 'you', 'fear', ',', 'make', 'it', 'work', 'for', 'you', '—', 'draw', '&', 'paint', 'your', 'fear', '&', 'anxieti', '.', 'and', 'stop', 'worri', 'about', 'big', ',', 'deep', 'thing', 'such', 'as', '“', 'to', 'decid', 'on', 'a', 'purpos', 'and', 'way', 'of', 'life', ',', 'a', 'consist', 'approach', 'to', 'even', 'some', 'imposs', 'end', 'or', 'even', 'an', 'imagin', 'end.', '”', 'you', 'must', 'practic', 'be', 'stupid', ',', 'dumb', ',', 'unthink', ',', 'empti', '.', 'then', 'you', 'will', 'be', 'abl', 'to', 'do', 'i', 'have', 'much', 'confid', 'in', 'you', 'and', 'even', 'though', 'you', 'are', 'torment', 'yourself', ',', 'the', 'work', 'you', 'do', 'is', 'veri', 'good', '.', 'tri', 'to', 'do', 'some', 'bad', 'work', '—', 'the', 'worst', 'you', 'can', 'think', 'of', 'and', 'see', 'what', 'happen', 'but', 'mainli', 'relax', 'and', 'let', 'everyth', 'go', 'to', 'hell', '—', 'you', 'are', 'not', 'respons', 'for', 'the', 'world', '—', 'you', 'are', 'onli', 'respons', 'for', 'your', 'work', '—', 'so', 'do', 'it', '.', 'and', 'don', '’', 't', 'think', 'that', 'your', 'work', 'ha', 'to', 'conform', 'to', 'ani', 'preconceiv', 'form', ',', 'idea', 'or', 'flavor', '.', 'it', 'can', 'be', 'anyth', 'you', 'want', 'it', 'to', 'be', '.', 'but', 'if', 'life', 'would', 'be', 'easier', 'for', 'you', 'if', 'you', 'stop', 'work', '—', 'then', 'stop', '.', 'don', '’', 't', 'punish', 'yourself', '.', 'howev', ',', 'i', 'think', 'that', 'it', 'is', 'so', 'deepli', 'engrain', 'in', 'you', 'that', 'it', 'would', 'be', 'easier', 'to', 'do', 'it', 'seem', 'i', 'do', 'understand', 'your', 'attitud', 'somewhat', ',', 'anyway', ',', 'becaus', 'i', 'go', 'through', 'a', 'similar', 'process', 'everi', 'so', 'often', '.', 'i', 'have', 'an', '“', 'agon', 'reapprais', '”', 'of', 'my', 'work', 'and', 'chang', 'everyth', 'as', 'much', 'as', 'possibl', '—', 'and', 'hate', 'everyth', 'i', '’', 've', 'done', ',', 'and', 'tri', 'to', 'do', 'someth', 'entir', 'differ', 'and', 'better', '.', 'mayb', 'that', 'kind', 'of', 'process', 'is', 'necessari', 'to', 'me', ',', 'push', 'me', 'on', 'and', 'on', '.', 'the', 'feel', 'that', 'i', 'can', 'do', 'better', 'than', 'that', 'shit', 'i', 'just', 'did', '.', 'mayb', 'you', 'need', 'your', 'agoni', 'to', 'accomplish', 'what', 'you', 'do', '.', 'and', 'mayb', 'it', 'goad', 'you', 'on', 'to', 'do', 'better', '.', 'but', 'it', 'is', 'veri', 'pain', 'i', 'know', '.', 'it', 'would', 'be', 'better', 'if', 'you', 'had', 'the', 'confid', 'just', 'to', 'do', 'the', 'stuff', 'and', 'not', 'even', 'think', 'about', 'it', '.', 'can', '’', 't', 'you', 'leav', 'the', '“', 'world', '”', 'and', '“', 'art', '”', 'alon', 'and', 'also', 'quit', 'fondl', 'your', 'ego', '.', 'i', 'know', 'that', 'you', '(', 'or', 'anyon', ')', 'can', 'onli', 'work', 'so', 'much', 'and', 'the', 'rest', 'of', 'the', 'time', 'you', 'are', 'left', 'with', 'your', 'thought', '.', 'but', 'when', 'you', 'work', 'or', 'befor', 'your', 'work', 'you', 'have', 'to', 'empti', 'your', 'mind', 'and', 'concentr', 'on', 'what', 'you', 'are', 'do', '.', 'after', 'you', 'do', 'someth', 'it', 'is', 'done', 'and', 'that', '’', 's', 'that', '.', 'after', 'a', 'while', 'you', 'can', 'see', 'some', 'are', 'better', 'than', 'other', 'but', 'also', 'you', 'can', 'see', 'what', 'direct', 'you', 'are', 'go', '.', 'i', '’', 'm', 'sure', 'you', 'know', 'all', 'that', '.', 'you', 'also', 'must', 'know', 'that', 'you', 'don', '’', 't', 'have', 'to', 'justifi', 'your', 'work', '—', 'not', 'even', 'to', 'yourself', '.', 'well', ',', 'you', 'know', 'i', 'admir', 'your', 'work', 'greatli', 'and', 'can', '’', 't', 'understand', 'whi', 'you', 'are', 'so', 'bother', 'by', 'it', '.', 'but', 'you', 'can', 'see', 'the', 'next', 'one', '&', 'i', 'can', '’', 't', '.', 'you', 'also', 'must', 'believ', 'in', 'your', 'abil', '.', 'i', 'think', 'you', 'do', '.', 'so', 'tri', 'the', 'most', 'outrag', 'thing', 'you', 'can', '—', 'shock', 'yourself', '.', 'you', 'have', 'at', 'your', 'power', 'the', 'abil', 'to', 'do', 'anyth', '.', 'i', 'would', 'like', 'to', 'see', 'your', 'work', 'and', 'will', 'have', 'to', 'be', 'content', 'to', 'wait', 'until', 'aug', 'or', 'sept', '.', 'i', 'have', 'seen', 'photo', 'of', 'some', 'of', 'tom', '’', 's', 'new', 'thing', 'at', 'luci', '’', 's', '.', 'they', 'are', 'veri', 'impress', '—', 'especi', 'the', 'one', 'with', 'the', 'more', 'rigor', 'form', ';', 'the', 'simpler', 'one', '.', 'i', 'guess', 'he', '’', 'll', 'send', 'some', 'more', 'later', 'on', '.', 'let', 'me', 'know', 'how', 'the', 'show', 'are', 'go', 'and', 'that', 'kind', 'of', 'stuff', '.', 'my', 'work', 'ha', 'chang', 'sinc', 'you', 'left', 'and', 'it', 'is', 'much', 'better', '.', 'i', 'will', 'be', 'have', 'a', 'show', 'may', '4–29', 'at', 'the', 'daniel', 'galleri', '17', 'e', '64th', 'st', '(', 'where', 'emmerich', 'wa', ')', ',', 'i', 'wish', 'you', 'could', 'be', 'there', '.', 'much', 'love', 'to', 'you', 'both', '.', 'sol']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sayed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sayed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Ensure punkt is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def tokenize_text_file(file_path):\n",
    "    \"\"\"Tokenizes the text in the given file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        tokens = word_tokenize(text)\n",
    "        return tokens\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} was not found.\")\n",
    "        return []\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error: Could not decode the file {file_path} due to encoding issue. {e}\")\n",
    "        return []\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    \"\"\"Applies stemming to each token using the Porter Stemmer.\"\"\"\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to your text file\n",
    "    file_path = r\"F:\\M.Tech_CollgeMaterials\\CodeLLM\\PracticalLabs\\Lb2\\letter.txt\"  # Update the path\n",
    "\n",
    "    # Call the function to tokenize the file content\n",
    "    tokens = tokenize_text_file(file_path)\n",
    "\n",
    "    if tokens:\n",
    "        print(\"Original Tokens:\")\n",
    "        print(tokens)\n",
    "\n",
    "        # Apply stemming to the tokens\n",
    "        stemmed_tokens = stem_tokens(tokens)\n",
    "        print(\"\\nStemmed Tokens:\")\n",
    "        print(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens:\n",
      "['Dear', 'Eva', ',', 'It', 'will', 'be', 'almost', 'a', 'month', 'since', 'you', 'wrote', 'to', 'me', 'and', 'you', 'have', 'possibly', 'forgotten', 'your', 'state', 'of', 'mind', '(', 'I', 'doubt', 'it', 'though', ')', '.', 'You', 'seem', 'the', 'same', 'as', 'always', ',', 'and', 'being', 'you', ',', 'hate', 'every', 'minute', 'of', 'it', '.', 'Don', '’', 't', '!', 'Learn', 'to', 'say', '“', 'Fuck', 'You', '”', 'to', 'the', 'world', 'once', 'in', 'a', 'while', '.', 'You', 'have', 'every', 'right', 'to', '.', 'Just', 'stop', 'thinking', ',', 'worrying', ',', 'looking', 'over', 'your', 'shoulder', ',', 'wondering', ',', 'doubting', ',', 'fearing', ',', 'hurting', ',', 'hoping', 'for', 'some', 'easy', 'way', 'out', ',', 'struggling', ',', 'grasping', ',', 'confusing', ',', 'itching', ',', 'scratching', ',', 'mumbling', ',', 'bumbling', ',', 'grumbling', ',', 'humbling', ',', 'stumbling', ',', 'numbling', ',', 'rambling', ',', 'gambling', ',', 'tumbling', ',', 'scumbling', ',', 'scrambling', ',', 'hitching', ',', 'hatching', ',', 'bitching', ',', 'moaning', ',', 'groaning', ',', 'honing', ',', 'boning', ',', 'horse-shitting', ',', 'hair-splitting', ',', 'nit-picking', ',', 'piss-trickling', ',', 'nose', 'sticking', ',', 'ass-gouging', ',', 'eyeball-poking', ',', 'finger-pointing', ',', 'alleyway-sneaking', ',', 'long', 'waiting', ',', 'small', 'stepping', ',', 'evil-eyeing', ',', 'back-scratching', ',', 'searching', ',', 'perching', ',', 'besmirching', ',', 'grinding', ',', 'grinding', ',', 'grinding', 'away', 'at', 'yourself', '.', 'Stop', 'it', 'and', 'just', 'DO', 'From', 'your', 'description', ',', 'and', 'from', 'what', 'I', 'know', 'of', 'your', 'previous', 'work', 'and', 'your', 'ability', ';', 'the', 'work', 'you', 'are', 'doing', 'sounds', 'very', 'good', '“', 'Drawing', '–', 'clean', '–', 'clear', 'but', 'crazy', 'like', 'machines', ',', 'larger', 'and', 'bolder…', 'real', 'nonsense.', '”', 'That', 'sounds', 'fine', ',', 'wonderful', '—', 'real', 'nonsense', '.', 'Do', 'more', '.', 'More', 'nonsensical', ',', 'more', 'crazy', ',', 'more', 'machines', ',', 'more', 'breasts', ',', 'penises', ',', 'cunts', ',', 'whatever', '—', 'make', 'them', 'abound', 'with', 'nonsense', '.', 'Try', 'and', 'tickle', 'something', 'inside', 'you', ',', 'your', '“', 'weird', 'humor.', '”', 'You', 'belong', 'in', 'the', 'most', 'secret', 'part', 'of', 'you', '.', 'Don', '’', 't', 'worry', 'about', 'cool', ',', 'make', 'your', 'own', 'uncool', '.', 'Make', 'your', 'own', ',', 'your', 'own', 'world', '.', 'If', 'you', 'fear', ',', 'make', 'it', 'work', 'for', 'you', '—', 'draw', '&', 'paint', 'your', 'fear', '&', 'anxiety', '.', 'And', 'stop', 'worrying', 'about', 'big', ',', 'deep', 'things', 'such', 'as', '“', 'to', 'decide', 'on', 'a', 'purpose', 'and', 'way', 'of', 'life', ',', 'a', 'consistant', 'approach', 'to', 'even', 'some', 'impossible', 'end', 'or', 'even', 'an', 'imagined', 'end.', '”', 'You', 'must', 'practice', 'being', 'stupid', ',', 'dumb', ',', 'unthinking', ',', 'empty', '.', 'Then', 'you', 'will', 'be', 'able', 'to', 'DO', 'I', 'have', 'much', 'confidence', 'in', 'you', 'and', 'even', 'though', 'you', 'are', 'tormenting', 'yourself', ',', 'the', 'work', 'you', 'do', 'is', 'very', 'good', '.', 'Try', 'to', 'do', 'some', 'BAD', 'work', '—', 'the', 'worst', 'you', 'can', 'think', 'of', 'and', 'see', 'what', 'happens', 'but', 'mainly', 'relax', 'and', 'let', 'everything', 'go', 'to', 'hell', '—', 'you', 'are', 'not', 'responsible', 'for', 'the', 'world', '—', 'you', 'are', 'only', 'responsible', 'for', 'your', 'work', '—', 'so', 'DO', 'IT', '.', 'And', 'don', '’', 't', 'think', 'that', 'your', 'work', 'has', 'to', 'conform', 'to', 'any', 'preconceived', 'form', ',', 'idea', 'or', 'flavor', '.', 'It', 'can', 'be', 'anything', 'you', 'want', 'it', 'to', 'be', '.', 'But', 'if', 'life', 'would', 'be', 'easier', 'for', 'you', 'if', 'you', 'stopped', 'working', '—', 'then', 'stop', '.', 'Don', '’', 't', 'punish', 'yourself', '.', 'However', ',', 'I', 'think', 'that', 'it', 'is', 'so', 'deeply', 'engrained', 'in', 'you', 'that', 'it', 'would', 'be', 'easier', 'to', 'DO', 'It', 'seems', 'I', 'do', 'understand', 'your', 'attitude', 'somewhat', ',', 'anyway', ',', 'because', 'I', 'go', 'through', 'a', 'similar', 'process', 'every', 'so', 'often', '.', 'I', 'have', 'an', '“', 'Agonizing', 'Reappraisal', '”', 'of', 'my', 'work', 'and', 'change', 'everything', 'as', 'much', 'as', 'possible', '—', 'and', 'hate', 'everything', 'I', '’', 've', 'done', ',', 'and', 'try', 'to', 'do', 'something', 'entirely', 'different', 'and', 'better', '.', 'Maybe', 'that', 'kind', 'of', 'process', 'is', 'necessary', 'to', 'me', ',', 'pushing', 'me', 'on', 'and', 'on', '.', 'The', 'feeling', 'that', 'I', 'can', 'do', 'better', 'than', 'that', 'shit', 'I', 'just', 'did', '.', 'Maybe', 'you', 'need', 'your', 'agony', 'to', 'accomplish', 'what', 'you', 'do', '.', 'And', 'maybe', 'it', 'goads', 'you', 'on', 'to', 'do', 'better', '.', 'But', 'it', 'is', 'very', 'painful', 'I', 'know', '.', 'It', 'would', 'be', 'better', 'if', 'you', 'had', 'the', 'confidence', 'just', 'to', 'do', 'the', 'stuff', 'and', 'not', 'even', 'think', 'about', 'it', '.', 'Can', '’', 't', 'you', 'leave', 'the', '“', 'world', '”', 'and', '“', 'ART', '”', 'alone', 'and', 'also', 'quit', 'fondling', 'your', 'ego', '.', 'I', 'know', 'that', 'you', '(', 'or', 'anyone', ')', 'can', 'only', 'work', 'so', 'much', 'and', 'the', 'rest', 'of', 'the', 'time', 'you', 'are', 'left', 'with', 'your', 'thoughts', '.', 'But', 'when', 'you', 'work', 'or', 'before', 'your', 'work', 'you', 'have', 'to', 'empty', 'your', 'mind', 'and', 'concentrate', 'on', 'what', 'you', 'are', 'doing', '.', 'After', 'you', 'do', 'something', 'it', 'is', 'done', 'and', 'that', '’', 's', 'that', '.', 'After', 'a', 'while', 'you', 'can', 'see', 'some', 'are', 'better', 'than', 'others', 'but', 'also', 'you', 'can', 'see', 'what', 'direction', 'you', 'are', 'going', '.', 'I', '’', 'm', 'sure', 'you', 'know', 'all', 'that', '.', 'You', 'also', 'must', 'know', 'that', 'you', 'don', '’', 't', 'have', 'to', 'justify', 'your', 'work', '—', 'not', 'even', 'to', 'yourself', '.', 'Well', ',', 'you', 'know', 'I', 'admire', 'your', 'work', 'greatly', 'and', 'can', '’', 't', 'understand', 'why', 'you', 'are', 'so', 'bothered', 'by', 'it', '.', 'But', 'you', 'can', 'see', 'the', 'next', 'ones', '&', 'I', 'can', '’', 't', '.', 'You', 'also', 'must', 'believe', 'in', 'your', 'ability', '.', 'I', 'think', 'you', 'do', '.', 'So', 'try', 'the', 'most', 'outrageous', 'things', 'you', 'can', '—', 'shock', 'yourself', '.', 'You', 'have', 'at', 'your', 'power', 'the', 'ability', 'to', 'do', 'anything', '.', 'I', 'would', 'like', 'to', 'see', 'your', 'work', 'and', 'will', 'have', 'to', 'be', 'content', 'to', 'wait', 'until', 'Aug', 'or', 'Sept', '.', 'I', 'have', 'seen', 'photos', 'of', 'some', 'of', 'Tom', '’', 's', 'new', 'things', 'at', 'Lucy', '’', 's', '.', 'They', 'are', 'very', 'impressive', '—', 'especially', 'the', 'ones', 'with', 'the', 'more', 'rigorous', 'form', ';', 'the', 'simpler', 'ones', '.', 'I', 'guess', 'he', '’', 'll', 'send', 'some', 'more', 'later', 'on', '.', 'Let', 'me', 'know', 'how', 'the', 'shows', 'are', 'going', 'and', 'that', 'kind', 'of', 'stuff', '.', 'My', 'work', 'has', 'changed', 'since', 'you', 'left', 'and', 'it', 'is', 'much', 'better', '.', 'I', 'will', 'be', 'having', 'a', 'show', 'May', '4–29', 'at', 'the', 'Daniels', 'Gallery', '17', 'E', '64th', 'St', '(', 'where', 'Emmerich', 'was', ')', ',', 'I', 'wish', 'you', 'could', 'be', 'there', '.', 'Much', 'love', 'to', 'you', 'both', '.', 'Sol']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sayed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sayed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sayed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sayed/nltk_data'\n    - 'c:\\\\Users\\\\sayed\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Users\\\\sayed\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\sayed\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sayed\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'F:\\\\M.Tech_CollgeMaterials\\\\CodeLLM\\\\PracticalLabs'\n    - 'F:\\\\M.Tech_CollgeMaterials\\\\CodeLLM\\\\PracticalLabs\\\\Lb1'\n    - 'F:\\\\M.Tech_CollgeMaterials\\\\CodeLLM\\\\PracticalLabs\\\\Lb1'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Apply POS tagging to the tokens\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m pos_tags \u001b[38;5;241m=\u001b[39m \u001b[43mpos_tag_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPart of Speech Tags:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(pos_tags)\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36mpos_tag_tokens\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos_tag_tokens\u001b[39m(tokens):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Performs Part of Speech (POS) tagging on the list of tokens.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sayed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tag\\__init__.py:168\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos_tag\u001b[39m(tokens, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32mc:\\Users\\sayed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tag\\__init__.py:110\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    108\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m PerceptronTagger(lang\u001b[38;5;241m=\u001b[39mlang)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32mc:\\Users\\sayed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tag\\perceptron.py:183\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load, lang)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sayed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tag\\perceptron.py:273\u001b[0m, in \u001b[0;36mPerceptronTagger.load_from_json\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# Automatically find path to the tagger if location is not specified.\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(loc \u001b[38;5;241m+\u001b[39m TAGGER_JSONS[lang][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fin)\n",
      "File \u001b[1;32mc:\\Users\\sayed\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sayed/nltk_data'\n    - 'c:\\\\Users\\\\sayed\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Users\\\\sayed\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\sayed\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sayed\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'F:\\\\M.Tech_CollgeMaterials\\\\CodeLLM\\\\PracticalLabs'\n    - 'F:\\\\M.Tech_CollgeMaterials\\\\CodeLLM\\\\PracticalLabs\\\\Lb1'\n    - 'F:\\\\M.Tech_CollgeMaterials\\\\CodeLLM\\\\PracticalLabs\\\\Lb1'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Ensure punkt and POS tagger are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')  # Download the POS tagger model\n",
    "nltk.download('universal_tagset')  # Download the universal tagset for better POS tagging\n",
    "\n",
    "def tokenize_text_file(file_path):\n",
    "    \"\"\"Tokenizes the text in the given file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        tokens = word_tokenize(text)\n",
    "        return tokens\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} was not found.\")\n",
    "        return []\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error: Could not decode the file {file_path} due to encoding issue. {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    \"\"\"Applies stemming to each token using the Porter Stemmer.\"\"\"\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "def pos_tag_tokens(tokens):\n",
    "    \"\"\"Performs Part of Speech (POS) tagging on the list of tokens.\"\"\"\n",
    "    try:\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        return pos_tags\n",
    "    except Exception as e:\n",
    "        print(f\"Error during POS tagging: {e}\")\n",
    "        return []\n",
    "\n",
    "def test_pos_tagging():\n",
    "    \"\"\"Test POS tagging on a small example.\"\"\"\n",
    "    sample_tokens = [\"This\", \"is\", \"a\", \"test\"]\n",
    "    pos_tags = pos_tag_tokens(sample_tokens)\n",
    "    if pos_tags:\n",
    "        print(\"\\nPOS Tagging Test Result:\")\n",
    "        print(pos_tags)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test POS tagging on a small example before processing the file\n",
    "    test_pos_tagging()\n",
    "\n",
    "    # Specify the path to your text file\n",
    "    file_path = r\"F:\\M.Tech_CollgeMaterials\\CodeLLM\\PracticalLabs\\Lb2\\letter.txt\"  # Update the path\n",
    "\n",
    "    # Call the function to tokenize the file content\n",
    "    tokens = tokenize_text_file(file_path)\n",
    "\n",
    "    if tokens:\n",
    "        print(\"Original Tokens:\")\n",
    "        print(tokens)\n",
    "\n",
    "        # Apply POS tagging to the tokens\n",
    "        pos_tags = pos_tag_tokens(tokens)\n",
    "        if pos_tags:\n",
    "            print(\"\\nPart of Speech Tags:\")\n",
    "            print(pos_tags)\n",
    "\n",
    "        # Apply stemming to the tokens\n",
    "        stemmed_tokens = stem_tokens(tokens)\n",
    "        print(\"\\nStemmed Tokens:\")\n",
    "        print(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
