import re
from youtube_comment_downloader import YoutubeCommentDownloader
from langdetect import detect
from deep_translator import GoogleTranslator
from transformers import pipeline
import torch

# Sentiment pipeline setup
device = 0 if torch.cuda.is_available() else -1
print("Device set to:", "cuda:0" if device == 0 else "cpu")
sentiment_analyzer = pipeline("sentiment-analysis", device=device)

# Extracts YouTube video ID
def extract_video_id(url):
    match = re.search(r"(?:v=|youtu\.be/)([a-zA-Z0-9_-]{11})", url)
    if not match:
        raise ValueError("Invalid YouTube URL")
    return match.group(1)

# Language detection
def is_english(text):
    try:
        return detect(text) == "en"
    except:
        return False

# Translate if not English
def translate_to_english(text):
    try:
        return GoogleTranslator(source='auto', target='en').translate(text)
    except Exception as e:
        return f"[Translation error] {text}"

# Fetch YouTube comments
def fetch_comments_scrape(url, max_comments=50):
    video_id = extract_video_id(url)
    downloader = YoutubeCommentDownloader()
    comments = []
    print("üí¨ Fetching comments...")

    try:
        for comment in downloader.get_comments_from_url(f"https://www.youtube.com/watch?v={video_id}"):
            text = comment["text"]
            if not is_english(text):
                text = translate_to_english(text)
            comments.append(text)
            if len(comments) >= max_comments:
                break
    except Exception as e:
        print(f"‚ùå Error fetching comments: {e}")
        return []

    return comments

# Perform sentiment analysis
def analyze_sentiment(comments):
    print("‚úÖ Performing sentiment analysis...")
    summary = {"POSITIVE": 0, "NEUTRAL": 0, "NEGATIVE": 0}
    detailed = []

    for comment in comments:
        try:
            result = sentiment_analyzer(comment)[0]
            label = result["label"]
            score = result["score"]

            if label == "POSITIVE":
                summary["POSITIVE"] += 1
            elif label == "NEGATIVE":
                summary["NEGATIVE"] += 1
            else:
                summary["NEUTRAL"] += 1

            detailed.append((comment, label, score))
        except Exception as e:
            detailed.append((comment, "ERROR", 0.0))

    return summary, detailed

# Main entry point
def main():
    url = input("üîó Enter YouTube video URL: ").strip()
    if not url:
        print("‚ùå No URL entered.")
        return

    comments = fetch_comments_scrape(url, max_comments=50)
    if not comments:
        print("‚ùå No comments to analyze.")
        return

    summary, detailed = analyze_sentiment(comments)

    print("\n--- Sentiment Analysis Summary ---")
    print("üü¢ POSITIVE:", summary["POSITIVE"])
    print("üü° NEUTRAL :", summary["NEUTRAL"])
    print("üî¥ NEGATIVE:", summary["NEGATIVE"])

    if summary["POSITIVE"] > summary["NEGATIVE"]:
        print("‚úÖ Overall Sentiment: Mostly Positive")
    elif summary["NEGATIVE"] > summary["POSITIVE"]:
        print("‚ö†Ô∏è Overall Sentiment: Mostly Negative")
    else:
        print("üìä Overall Sentiment: Mixed or Neutral")

    print("\nüìã Detailed Comment Analysis:")
    for i, (comment, label, score) in enumerate(detailed, 1):
        print(f"{i}. {comment}")
        print(f"   Sentiment: {label}, Score: {round(score, 3)}")

# Intent classification pipeline
intent_classifier = pipeline(
    "text-classification",
    model="bhadresh-savani/distilbert-base-uncased-emotion",  # Temp model: classify emotion/intent-like labels
    device=device
)
# Analyze intent of comments
def analyze_intent(comments):
    print("‚úÖ Performing intent classification...")
    intent_summary = {}
    intent_detailed = []

    # Intent label mapping
    INTENT_MAP = {
        "joy": "Praise",
        "anger": "Complaint",
        "sadness": "Complaint",
        "surprise": "Request",
        "love": "Praise",
        "fear": "Concern",
    }

    for comment in comments:
        try:
            result = intent_classifier(comment)[0]
            raw_label = result["label"]
            score = result["score"]

            # Normalize label using intent map
            label = INTENT_MAP.get(raw_label, raw_label)

            # Count summary
            if label not in intent_summary:
                intent_summary[label] = 0
            intent_summary[label] += 1

            intent_detailed.append((comment, label, score))
        except Exception as e:
            intent_detailed.append((comment, "ERROR", 0.0))

    return intent_summary, intent_detailed


if __name__ == "__main__":
    main()
